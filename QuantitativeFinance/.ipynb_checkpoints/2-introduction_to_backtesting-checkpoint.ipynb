{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to backtesting trading strategies using `zipline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn how to build and backtest trading strategies using `zipline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, I would like to continue the series on quantitative finance. In the [first part](https://towardsdatascience.com/introduction-to-quantitative-finance-part-i-stylised-facts-of-asset-returns-5190581e40ea), I described the stylized facts of asset returns. Now I would like to introduce the concept of backtesting trading strategies and how to do it using existing frameworks in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is backtesting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a trading strategy. It can be defined as a method of buying and/or selling assets in markets that is based on predefined rules. These rules can be based on, for example, technical analysis or machine learning models.\n",
    "\n",
    "Backtesting is basically evaluating the performance of a trading strategy on historical data - if we used a given strategy on a set of assets in the past, how well/bad would it have performed. Of course, there is no guarantee that past performance is indicative of the future one, but we can still investigate!\n",
    "\n",
    "There are a few available frameworks for backtesting in Python, in this article, I decided to use `zipline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why zipline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the nice features offered by the `zipline` environment include:\n",
    "* ease of use - there is a clear structure of how to build a backtest and what outcome we can expect, so the majority of the time can be spent on developing state-of-the-art trading strategies :)\n",
    "* realistic - includes transaction costs, slippage, order delays, etc.\n",
    "* stream-based - processes each event individually, thus avoids look-ahead bias\n",
    "* it comes with many easily-accessible statistical measures, such as moving average, linear regression, etc. - no need to code them from scratch\n",
    "* integration with PyData ecosystem - `zipline` uses Pandas DataFrames for storing input data, as well as performance metrics\n",
    "* it is easy to integrate other libraries, such as `matplotlib`, `scipy`, `statsmodels` and `sklearn` into the workflow of building and evaluating strategies\n",
    "* developed and updated by Quantopian which provides a web-interface for `zipline`, historical data and even live-trading capabilities\n",
    "\n",
    "I believe these arguments speak for themselves. Let's start coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the virtual environment using conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most convenient way to install `zipline` is to use a virtual environment. In this article, I use `conda` to do so. I create a new environment with Python 3.5 (I experienced issues with using 3.6 or 3.7) and then install `zipline`. You can also `pip install` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new virtual environment\n",
    "#conda create -n env_zipline python=3.5\n",
    "\n",
    "# activate it\n",
    "#conda activate env_zipline\n",
    "\n",
    "# install zipline\n",
    "#conda install -c Quantopian zipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For everything to be working properly you should also install `jupyter` and other packages used in this article (see the `watermark` printout below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load IPython extensions using the `%load_ext` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6 (default, Oct 16 2018, 07:17:20) \n",
      "[GCC 6.3.0 20170516]\n",
      "1.19.5\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:22:03.611280Z",
     "start_time": "2019-08-02T12:22:03.592716Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:22:05.324870Z",
     "start_time": "2019-08-02T12:22:03.837117Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext zipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:22:09.440840Z",
     "start_time": "2019-08-02T12:22:09.079439Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the rest of the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:22:09.761619Z",
     "start_time": "2019-08-02T12:22:09.597402Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import zipline\n",
    "from trading_calendars import get_calendar\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the list of libraries used in this article, together with their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T12:22:10.647261Z",
     "start_time": "2019-08-02T12:22:10.643644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy    1.19.5\n",
      "zipline  1.6.1+6.gacc6dde7.dirty\n",
      "pandas   0.25.3\n",
      "yfinance 0.1.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zipline` comes ready with data downloaded from Quandl (the WIKI database). You can always inspect the already ingested data by running: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T07:35:10.611378Z",
     "start_time": "2019-08-02T07:35:08.653425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca_api <no ingestions>\r\n",
      "alpha_vantage <no ingestions>\r\n",
      "csvdir <no ingestions>\r\n",
      "quandl <no ingestions>\r\n",
      "quantopian-quandl <no ingestions>\r\n"
     ]
    }
   ],
   "source": [
    "!zipline bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this approach is that in mid 2018 the data was discontinued, so there is no data for the last year. To overcome this, I show how to manually ingest data from any source. To do so I use the `yahoofinancials` library. In order to be loaded into `zipline`, the data must be in a CSV file and in a predefined format - like the one on the preview of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start, end, codelist):\n",
    "  data = yf.download(codelist, start, end)\n",
    "  # display start date of each stock\n",
    "#  for i in codelist:\n",
    "#    display(data[i].dropna().head(1))\n",
    "\n",
    "  data=data.interpolate('time') # 欠損データを補間\n",
    "  #data_drop=data.dropna() # 欠損データを落とす    \n",
    "\n",
    "  return data# Adjusted Close (配当込み，分割調整値) の列を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>28.950001</td>\n",
       "      <td>29.082500</td>\n",
       "      <td>28.690001</td>\n",
       "      <td>29.037500</td>\n",
       "      <td>27.413372</td>\n",
       "      <td>115127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>28.962500</td>\n",
       "      <td>29.127501</td>\n",
       "      <td>28.937500</td>\n",
       "      <td>29.004999</td>\n",
       "      <td>27.382690</td>\n",
       "      <td>84472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>28.980000</td>\n",
       "      <td>29.215000</td>\n",
       "      <td>28.952499</td>\n",
       "      <td>29.152500</td>\n",
       "      <td>27.521944</td>\n",
       "      <td>88774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>29.195000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.117500</td>\n",
       "      <td>29.477501</td>\n",
       "      <td>27.828764</td>\n",
       "      <td>127007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>29.487499</td>\n",
       "      <td>29.857500</td>\n",
       "      <td>29.485001</td>\n",
       "      <td>29.747499</td>\n",
       "      <td>28.083660</td>\n",
       "      <td>134247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>133.410004</td>\n",
       "      <td>135.250000</td>\n",
       "      <td>133.350006</td>\n",
       "      <td>134.779999</td>\n",
       "      <td>134.779999</td>\n",
       "      <td>62111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>134.800003</td>\n",
       "      <td>136.490005</td>\n",
       "      <td>134.350006</td>\n",
       "      <td>136.330002</td>\n",
       "      <td>136.330002</td>\n",
       "      <td>64556100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>136.169998</td>\n",
       "      <td>137.410004</td>\n",
       "      <td>135.869995</td>\n",
       "      <td>136.960007</td>\n",
       "      <td>136.960007</td>\n",
       "      <td>63261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>136.600006</td>\n",
       "      <td>137.330002</td>\n",
       "      <td>135.759995</td>\n",
       "      <td>137.270004</td>\n",
       "      <td>137.270004</td>\n",
       "      <td>52485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-02</th>\n",
       "      <td>137.899994</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>139.960007</td>\n",
       "      <td>139.960007</td>\n",
       "      <td>78852600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1133 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2017-01-03   28.950001   29.082500   28.690001   29.037500   27.413372   \n",
       "2017-01-04   28.962500   29.127501   28.937500   29.004999   27.382690   \n",
       "2017-01-05   28.980000   29.215000   28.952499   29.152500   27.521944   \n",
       "2017-01-06   29.195000   29.540001   29.117500   29.477501   27.828764   \n",
       "2017-01-09   29.487499   29.857500   29.485001   29.747499   28.083660   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-06-28  133.410004  135.250000  133.350006  134.779999  134.779999   \n",
       "2021-06-29  134.800003  136.490005  134.350006  136.330002  136.330002   \n",
       "2021-06-30  136.169998  137.410004  135.869995  136.960007  136.960007   \n",
       "2021-07-01  136.600006  137.330002  135.759995  137.270004  137.270004   \n",
       "2021-07-02  137.899994  140.000000  137.750000  139.960007  139.960007   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2017-01-03  115127600  \n",
       "2017-01-04   84472400  \n",
       "2017-01-05   88774400  \n",
       "2017-01-06  127007600  \n",
       "2017-01-09  134247600  \n",
       "...               ...  \n",
       "2021-06-28   62111300  \n",
       "2021-06-29   64556100  \n",
       "2021-06-30   63261400  \n",
       "2021-07-01   52485800  \n",
       "2021-07-02   78852600  \n",
       "\n",
       "[1133 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker = ['AAPL']\n",
    "date_start = '2017-01-01' #@param {type:\"date\"}\n",
    "start = datetime.datetime.strptime(date_start, '%Y-%m-%d')\n",
    "end = datetime.date.today()\n",
    "\n",
    "df = get_data(start, end, ticker)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:23:28.742793Z",
     "start_time": "2019-07-27T19:23:28.412303Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AAPL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AAPL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c93a88ec7708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'formatted_date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'low'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dividend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AAPL'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df[ticker[0]]['prices']).drop(['date'], axis=1).rename(columns={'formatted_date':'date'})\n",
    "df = df[['date','open','high','low','close','volume']]\n",
    "df['dividend'] = 0\n",
    "df['split'] = 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to save the data as a CSV file in a folder called 'daily' (or another folder of your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T14:03:36.466073Z",
     "start_time": "2019-07-19T14:03:36.453053Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('daily/aapl.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we need to modify the `extension.py` file located in the zipline directory. After the installation of `zipline` it is empty and we need to add the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from zipline.data.bundles import register\n",
    "from zipline.data.bundles.csvdir import csvdir_equities\n",
    "\n",
    "start_session = pd.Timestamp('2017-01-03', tz='utc')\n",
    "end_session = pd.Timestamp('2019-06-28', tz='utc')\n",
    "\n",
    "# register the bundle \n",
    "register(\n",
    "    'apple-prices-2017-2019', # name we select for the bundle\n",
    "    csvdir_equities(\n",
    "        ['daily'], # name of the directory as specified above (named after data frequency)\n",
    "        '/path/to/directory/with/csv', # path to directory containing the data\n",
    "    ),\n",
    "    calendar_name='NYSE',  # US equities\n",
    "    start_session=start_session,\n",
    "    end_session=end_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define and provide a custom calendar to the data-ingesting script - for example when working with European stocks. For details on how to do it please look at the [documentation](https://www.zipline.io/trading-calendars.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the data downloading function, we need to pass the exact range of dates of the downloaded data. In this example, we start with `2017-01-03`, as this is the first day for which we have pricing data. \n",
    "\n",
    "Lastly, we run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T14:03:40.092196Z",
     "start_time": "2019-07-19T14:03:37.445748Z"
    }
   },
   "outputs": [],
   "source": [
    "!zipline ingest -b apple-prices-2017-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the bundle was successfully ingested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T14:04:25.275731Z",
     "start_time": "2019-07-19T14:04:23.346170Z"
    }
   },
   "outputs": [],
   "source": [
    "!zipline bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [known issue](https://github.com/quantopian/zipline/issues/2480) with downloading the benchmark data, so - for now - we stick to historical data in the default bundle. However, you now know how to ingest data using a custom csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buy And Hold Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the most basic strategy - Buy and Hold. The idea is that we buy a certain asset and do not do anything for the entire duration of the investment horizon. This simple strategy can also be considered a benchmark for more advanced ones - because there is no point in using a very complex strategy that generates less money (for example due to transaction costs) than buying and doing nothing.\n",
    "\n",
    "In this example, we consider Apple's stock and select years 2016–2017 as the duration of the backtest. We start with a capital of 1050 USD. I selected this number as I know how much more or less we need to have for the initial purchase and I like to keep this number as small as possible because we are only buying 10 shares, so no need for a starting balance of a couple of thousands. We assume the default transaction costs (0.001$ per share, without a minimum cost per trade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two approaches to using `zipline` - using the command line or Jupyter Notebook. To use the latter we have to write the algorithm within a Notebook cell and indicate that `zipline` is supposed to run it. This is done via the `%%zipline` IPython magic command. This magic takes the same arguments as the CLI mentioned above. \n",
    "\n",
    "Also one important thing, all imports required for the algorithm to run (such as `numpy`, `sklearn`, etc.) must be specified in the algorithm cell, even if they were previously imported elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T17:14:10.009240Z",
     "start_time": "2019-07-28T17:14:08.696056Z"
    }
   },
   "outputs": [],
   "source": [
    "%%zipline --start 2016-1-1 --end 2017-12-31 --capital-base 1050.0 -o buy_and_hold.pkl\n",
    "\n",
    "# imports\n",
    "from zipline.api import order, symbol, record\n",
    "\n",
    "# parameters\n",
    "selected_stock = 'AAPL'\n",
    "n_stocks_to_buy = 10\n",
    "\n",
    "def initialize(context):\n",
    "    context.has_ordered = False  \n",
    "\n",
    "def handle_data(context, data):\n",
    "    # record price for further inspection\n",
    "    record(price=data.current(symbol(selected_stock), 'price'))\n",
    "    \n",
    "    # trading logic\n",
    "    if not context.has_ordered:\n",
    "        # placing order, negative number for sale/short\n",
    "        order(symbol(selected_stock), n_stocks_to_buy)\n",
    "        # setting up a flag for holding a position\n",
    "        context.has_ordered = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, we have written our first backtest. So what actually happened?\n",
    "\n",
    "Each `zipline` algorithm contains (at least) two functions we have to define:\n",
    "* `initialize(context)` \n",
    "* `handle_data(context, data)`\n",
    "\n",
    "Before the algorithm starts, the `initialize()` function is called and a `context` variable is passed. `context` is a global variable in which we can store additional variables we need to access from one iteration of the algorithm to the next.\n",
    "\n",
    "After the initialization of the algorithm, the `handle_data()` function is called once for each event. At every call, it passes the same `context` variable and an event frame called `data`. It contains the current trading bar with open, high, low, and close (OHLC) prices together with the volume.\n",
    "\n",
    "We create an order by using `order(asset, number_of_units)`, where we specify what to buy and how many shares/units. A positive number indicates buying that many shares, 0 means selling everything we have, and a negative number is used for short-selling. Another useful type of order is `order_target`, which orders as many shares as needed to achieve the desired number in the portfolio.\n",
    "\n",
    "In our Buy and Hold strategy, we check if we have already placed an order. If not, we order a given amount of shares and then do nothing for the rest of the backtest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the performance of the strategy. First, we need to load the performance DataFrame from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T17:14:10.177780Z",
     "start_time": "2019-07-28T17:14:10.170208Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the performance summary dataframe\n",
    "buy_and_hold_results = pd.read_pickle('buy_and_hold.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot some of the stored metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T17:14:12.657970Z",
     "start_time": "2019-07-28T17:14:10.395831Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=[16, 9])\n",
    "\n",
    "# portfolio value\n",
    "buy_and_hold_results.portfolio_value.plot(ax=ax[0])\n",
    "ax[0].set_ylabel('portfolio value in $')\n",
    "\n",
    "# asset\n",
    "buy_and_hold_results.price.plot(ax=ax[1])\n",
    "ax[1].set_ylabel('price in $')\n",
    "\n",
    "# mark transactions\n",
    "perf_trans = buy_and_hold_results.loc[[t != [] for t in buy_and_hold_results.transactions]]\n",
    "buys = perf_trans.loc[[t[0]['amount'] > 0 for t in perf_trans.transactions]]\n",
    "sells = perf_trans.loc[[t[0]['amount'] < 0 for t in perf_trans.transactions]]\n",
    "ax[1].plot(buys.index, buy_and_hold_results.price.loc[buys.index], '^', markersize=10, color='g', label='buy')\n",
    "ax[1].plot(sells.index, buy_and_hold_results.price.loc[sells.index], 'v', markersize=10, color='r', label='sell')\n",
    "\n",
    "# daily returns\n",
    "buy_and_hold_results.returns.plot(ax=ax[2])\n",
    "ax[2].set_ylabel('daily returns')\n",
    "\n",
    "fig.suptitle('Buy and Hold Strategy - Apple', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Final portfolio value (including cash): {}$'.format(np.round(buy_and_hold_results.portfolio_value[-1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first look we see that the portfolio generated money over the investment horizon and was very much following the price of Apple (what makes sense as it is the only asset in the portfolio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the transactions we need to transform the `transactions` column from the performance `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T17:12:46.203502Z",
     "start_time": "2019-07-28T17:12:46.186844Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records([x[0] for x in buy_and_hold_results.transactions.values if x != []])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the columns of the performance `DataFrame` we can see all the available metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T19:24:00.071460Z",
     "start_time": "2019-07-27T19:24:00.065933Z"
    }
   },
   "outputs": [],
   "source": [
    "buy_and_hold_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the noteworthy ones:\n",
    "* starting/ending cash - inspecting the cash holding on a given day\n",
    "* starting/ending value - inspecting the assets; value on a given day\n",
    "* orders - used for inspecting orders; there are different events for creating an order when the trading strategy generates a signal, and a separate one when it is actually executed on the next trading day\n",
    "* pnl - daily profit and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Simple Moving Average Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second strategy we consider is based on the simple moving average (SMA). The 'mechanics' of the strategy can be summarized by the following:\n",
    "\n",
    "* when the price crosses the 20-day SMA upwards - buy x shares\n",
    "* when the price crosses the 20-day SMA downwards - sell the shares\n",
    "* we can only have a maximum of x shares at any given time\n",
    "* there is no short-selling in the strategy (though it can be easily implemented)\n",
    "\n",
    "The remaining components of the backtest like the considered asset, investment horizon or the starting capital is the same as in the Buy and Hold example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T17:15:27.568079Z",
     "start_time": "2019-07-28T17:15:23.137349Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%zipline --start 2016-1-1 --end 2017-12-31 --capital-base 1050.0 -o sma_strategy.pkl\n",
    "\n",
    "# imports \n",
    "from zipline.api import order_target, record, symbol\n",
    "from zipline.finance import commission\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# parameters \n",
    "ma_periods = 20\n",
    "selected_stock = 'AAPL'\n",
    "n_stocks_to_buy = 10\n",
    "\n",
    "def initialize(context):\n",
    "    context.time = 0\n",
    "    context.asset = symbol(selected_stock)\n",
    "    # 1. manually setting the commission\n",
    "    context.set_commission(commission.PerShare(cost=0.001, min_trade_cost=0))\n",
    "\n",
    "def handle_data(context, data):\n",
    "    # 2. warm-up period\n",
    "    context.time += 1\n",
    "    if context.time < ma_periods:\n",
    "        return\n",
    "\n",
    "    # 3. access price history\n",
    "    price_history = data.history(context.asset, fields=\"price\", bar_count=ma_periods, frequency=\"1d\")\n",
    " \n",
    "    # 4. calculate moving averages\n",
    "    ma = price_history.mean()\n",
    "    \n",
    "    # 5. trading logic\n",
    "    \n",
    "    # cross up\n",
    "    if (price_history[-2] < ma) & (price_history[-1] > ma):\n",
    "        order_target(context.asset, n_stocks_to_buy)\n",
    "    # cross down\n",
    "    elif (price_history[-2] > ma) & (price_history[-1] < ma):\n",
    "        order_target(context.asset, 0)\n",
    "\n",
    "    # save values for later inspection\n",
    "    record(price=data.current(context.asset, 'price'),\n",
    "           moving_average=ma)\n",
    "    \n",
    "# 6. analyze block\n",
    "def analyze(context, perf):\n",
    "    fig, ax = plt.subplots(3, 1, sharex=True, figsize=[16, 9])\n",
    "\n",
    "    # portfolio value\n",
    "    perf.portfolio_value.plot(ax=ax[0])\n",
    "    ax[0].set_ylabel('portfolio value in $')\n",
    "    \n",
    "    # asset\n",
    "    perf[['price', 'moving_average']].plot(ax=ax[1])\n",
    "    ax[1].set_ylabel('price in $')\n",
    "    \n",
    "    # mark transactions\n",
    "    perf_trans = perf.loc[[t != [] for t in perf.transactions]]\n",
    "    buys = perf_trans.loc[[t[0]['amount'] > 0 for t in perf_trans.transactions]]\n",
    "    sells = perf_trans.loc[[t[0]['amount'] < 0 for t in perf_trans.transactions]]\n",
    "    ax[1].plot(buys.index, perf.price.loc[buys.index], '^', markersize=10, color='g', label='buy')\n",
    "    ax[1].plot(sells.index, perf.price.loc[sells.index], 'v', markersize=10, color='r', label='sell')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    # daily returns\n",
    "    perf.returns.plot(ax=ax[2])\n",
    "    ax[2].set_ylabel('daily returns')\n",
    "\n",
    "    fig.suptitle('Simple Moving Average Strategy - Apple', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('Final portfolio value (including cash): {}$'.format(np.round(perf.portfolio_value[-1], 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this algorithm is a little bit more complex, but we will cover all the new aspects of the code. For simplicity, I marked the points of reference in the code snippet above and will refer to them by number below.\n",
    "\n",
    "1. I show how to manually set the commission. In this case, I use the default value for comparison's sake.\n",
    "2. The \"warm-up period\" - this is a trick used in order to make sure that the algorithm has enough days to calculate the moving average. If we are using multiple metrics with different window lengths, we should always take the longest one for the warm-up. \n",
    "3. We access the historical (and current) data-points by using `data.history`. In this example, we access the last 20 days. The data (in case of a single asset) is stored as a `pandas.Series`, indexed by time.\n",
    "4. The SMA is a very basic measure, so for calculation, I simply take the mean of the previously accessed data.\n",
    "5. I encapsulate the logic of the trading strategy in an `if` statement. To access the current and previous data-points I use `price_history[-2]` and `price_history[-1]`, respectively. To see if there was a crossover, I compare the current and previous prices to the MA and determine which case I am dealing with (buy/sell signal). In the case where there is no signal, the algorithm does nothing.\n",
    "6. You can use the `analyze(context, perf)` statement to carry out extra analysis (like plotting) when the backtest is finished. The `perf` object is simply the performance `DataFrame` we also store in a pickle file. But when used withing the algorithm, we should refer to it as `perf` and there is no need for loading it.\n",
    "\n",
    "As compared to the Buy and Hold strategy, you might have noticed the periods where the portfolio value is flat. That is because when we sell the asset (and before buying again), we only hold cash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the Simple Moving Average strategy outperformed the Buy and Hold one. The ending worth of the portfolio (including cash) is 1784.12 USD for the SMA strategy, while it is 1714.68 USD in case of the simpler one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, I have shown how to use the `zipline` framework to carry out the backtesting of trading strategies. Once you get familiar with the library, it is easy to test out different strategies. In a future article, I will cover using more advanced trading strategies based on technical analysis. \n",
    "\n",
    "As always, any constructive feedback is welcome. You can reach out to me on [Twitter](https://twitter.com/erykml1) or in the comments. You can find the code used for this article on my [GitHub]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
